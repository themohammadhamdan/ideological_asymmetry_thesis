{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19f82f5a-2143-4a17-886d-0052f3c4830d",
   "metadata": {},
   "source": [
    "In this script we conduct our exploratory analysis, including constructing neural RDMs and conducting an IS-RSA. We loop over all nodes and then determine which of the 268 exhibit exhibit asynchrony between subjects relative to their identity, ideology, SES, gender and education. The nodes which have a significant difference will then be included in our confirmatory analysis as pre-defined regions of interest (ROIs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d689a4-0a32-493e-b5d6-ca23faec72d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "\n",
    "# general\n",
    "import os\n",
    "\n",
    "# for data wrangling/management and non-MRI calculations \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.stats import rankdata, ttest_rel, ttest_1samp\n",
    "import statsmodels.stats.multitest\n",
    "from joblib import Parallel, delayed\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# for plotting\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.transforms as mtransforms\n",
    "\n",
    "# for fMRI\n",
    "import nibabel as nib\n",
    "from nilearn.input_data import NiftiLabelsMasker, NiftiMasker\n",
    "from nilearn.plotting import plot_glass_brain, plot_stat_map, view_img, view_img_on_surf\n",
    "from nltools.data import Brain_Data, Adjacency\n",
    "from nltools.mask import roi_to_brain, expand_mask\n",
    "from nltools.stats import fdr, threshold\n",
    "from nltools import Brain_Data\n",
    "\n",
    "#import glob\n",
    "#import datalad.api as dl\n",
    "#from pathlib import Path\n",
    "#import seaborn as sns\n",
    "#from datetime import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# setting work and data directories\n",
    "csv_directory = os.path.dirname(\"/home/c13572687/Documents/scripts_and_data/csv_data/\") # this on the server\n",
    "fmri_directory = os.path.dirname(\"/home/c13572687/Documents/scripts_and_data/fmri_data/\") # this on the server\n",
    "\n",
    "# loading data\n",
    "exploratory_data = pd.read_csv(str(csv_directory + \"/exploratory_half.csv\"), sep = ',')\n",
    "exploratory_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe76290c-362a-42d8-912f-f0b7074bbf3b",
   "metadata": {},
   "source": [
    "Loading in Shen mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a538ed5-6339-4afc-9d71-d0fc5efaeb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = Brain_Data('https://neurovault.org/media/images/8423/shen_2mm_268_parcellation.nii.gz')\n",
    "mask.plot()\n",
    "\n",
    "masker = NiftiLabelsMasker(labels_img=mask.to_nifti(), standardize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c71af2-2652-4205-a32e-05272a5683aa",
   "metadata": {},
   "source": [
    "We need to load in the data, then per-subject per-run we need to resample and apply the mask, then create a node-wise time series. In the following cell we create a function which does this, and in the cell after we run it for 20 subjects simulatenously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587168f5-cf9e-4d46-990c-64e37fbff550",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_list = np.arange(0,5,1) #len(exploratory_data['participant_id']),1)\n",
    "\n",
    "def get_ts(subject):\n",
    "    for run in [1, 2, 3]:\n",
    "        this_subject = exploratory_data['participant_id'][subject]\n",
    "        fmri_filename = os.path.join(fmri_directory, exploratory_data['participant_id'][subject], 'func', str(exploratory_data['participant_id'][subject] + '_task-moviewatching_bold.nii.gz'))\n",
    "        print(f\"Creating node time series for {this_subject}, run {run}\")\n",
    "        \n",
    "        # we need to resample first, then apply the mask\n",
    "        brain_data = Brain_Data(fmri_filename)\n",
    "        time_series_fname = os.path.join(fmri_directory, this_subject, 'func', str(f'{this_subject}_run-{run}_nodeTimeSeries.csv'))\n",
    "        time_series = masker.fit_transform(fmri_filename) #(brain_data.to_nifti())\n",
    "        pd.DataFrame(time_series).to_csv(time_series_fname, index=False)\n",
    "    return\n",
    "\n",
    "Parallel(n_jobs=20)(delayed(get_ts)(subject) for (subject) in subj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c663a63-d651-42b7-b223-d15ae2d6bd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts(subject):\n",
    "    for run in [1, 2, 3]:\n",
    "        this_subject = exploratory_data['participant_id'][subject]\n",
    "        fmri_filename = os.path.join(fmri_directory, exploratory_data['participant_id'][subject], 'func', str(exploratory_data['participant_id'][subject] + '_task-moviewatching_bold.nii.gz'))\n",
    "        print(f\"Creating node time series for {this_subject}, run {run}\")\n",
    "        \n",
    "        # we need to resample first, then apply the mask\n",
    "        brain_data = Brain_Data(fmri_filename)\n",
    "        time_series_fname = os.path.join(fmri_directory, this_subject, 'func', str(f'{this_subject}_run-{run}_nodeTimeSeries.csv'))\n",
    "        time_series = masker.fit_transform(brain_data.to_nifti())\n",
    "        pd.DataFrame(time_series).to_csv(time_series_fname, index=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7241a6b-d11f-40fd-bf77-a00bd752f877",
   "metadata": {},
   "source": [
    "We now have to add all runs from all subjects into a `numpy` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891ad6df-1d59-4af4-8fd7-2123d828e2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_list = np.arange(0,len(exploratory_data['participant_id']),1)\n",
    "data = []\n",
    "\n",
    "for subj in tqdm(subj_list):\n",
    "    this_subject = exploratory_data['participant_id'][subj]\n",
    "    sub_data = []\n",
    "    for run in range(1,4):\n",
    "        current_file = pd.read_csv(os.path.join(fmri_directory, this_subject, 'func', str(f'{this_subject}_run-{run}_nodeTimeSeries.csv')))\n",
    "        sub_data.append(current_file)\n",
    "    sub_data = pd.concat(sub_data)\n",
    "    data.append(sub_data.values)\n",
    "\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a242d3f5-ab6d-4f6d-846f-60ed33c709cd",
   "metadata": {},
   "source": [
    "We should check that we have the correct data structure, which is number of subjects x number of time points across all 3 runs x number of nodes. For our data this should be 427 x 870 x 268."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6eb7a7-f15a-4e61-b43a-212770530e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "n_subs, n_ts, n_nodes = data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2659008e-db34-4626-ae82-f33754aa1e60",
   "metadata": {},
   "source": [
    "We will now visualize our similarity matrix and see that it makes sense (i.e., that there are different colours which indicate different correlations between subjects for a particular node):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5bae26-33a8-4d19-9740-78bcac682f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrices = []\n",
    "for node in tqdm(range(n_nodes)):\n",
    "    similarity_matrices.append(Adjacency(1 - pairwise_distances(data[:, :, node], metric='correlation'), matrix_type='distance'))\n",
    "similarity_matrices = Adjacency(similarity_matrices)\n",
    "\n",
    "saving_directory = os.path.dirname(\"/home/c13572687/Documents/scripts_and_data/figures/exploratory/\")\n",
    "\n",
    "random_nodes = np.random.randint(0, 267, 3)\n",
    "for node in random_nodes:\n",
    "    node = 267\n",
    "    plt.figure()\n",
    "    similarity_matrices[node].plot(vmin=-.25, vmax=.25, cmap='RdBu_r')    \n",
    "    plt.title(str(\"Visualizing similarity matrix for node \" + str(node)))\n",
    "    plt.savefig(os.path.join(saving_directory + '/RDMs/new/exploratory-RDM-node_' + str(node) + 'for_presentation.png'), dpi = 500)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c60eea-1a64-4498-96c8-9de8e1cbbe96",
   "metadata": {},
   "source": [
    "Next, we calculate and plot the intersubject synchrony of each of our 268 nodes (where a darker colour indicates a higher synchrony).\n",
    "Sanity check: early cortical areas (such as the early visual and auditory cortexes) appear to be more synchronous!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fb888a-db66-4241-88ad-0727e5ff319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "isc = {node:similarity_matrices[node].isc(metric='mean', n_bootstraps=1, n_jobs=1)['isc'] for node in range(n_nodes)}\n",
    "isc_p = {node:similarity_matrices[node].isc(metric='mean', n_bootstraps=1, n_jobs=1)['p'] for node in range(n_nodes)}\n",
    "mask_x = expand_mask(mask)\n",
    "isc_brain = roi_to_brain(pd.Series(isc), mask_x)\n",
    "plot_glass_brain(isc_brain.to_nifti(), colorbar = True, cmap = 'RdBu_r', plot_abs = True)#, #title = \"Mean Correlation Across Subjects\")\n",
    "\n",
    "#plt.savefig(os.path.join(saving_directory + '/brains/synchrony.png'), dpi = 500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a0b6cf-19cd-4e11-a279-517329695ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "isc_dict = {}\n",
    "for node in tqdm(range(268)):\n",
    "    isc_dict[node] = similarity_matrices[node].isc(metric = \"mean\", n_bootstraps = 500, n_jobs = 20)\n",
    "isc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735d3fda-cb61-4a6b-8f51-2514993b7a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.join(\"Documents/scripts_and_data/numpy_files_analysis/exploratory/\")\n",
    "np.save(\"isc_exploratory.npy\", isc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b527b418-d3b8-4c24-a860-01d351b073b3",
   "metadata": {},
   "source": [
    "Now we'll load our behavioural data and produce RDMs using the Euclidean distance, firstly in a nearest neighbor (NN) model, then in an Anna-K (AK), then a Mahalanobis Distance (MD) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c163aa5e-aebe-43bb-b344-dc8e1441ef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = np.array([\"social.ideology.scale\", \"social.identity.scale\", \n",
    "                      \"education_level\", \"background_SES\", \"sex\"])\n",
    "\n",
    "behav_sims_nn = dict()\n",
    "for variable in variables:\n",
    "    behav = exploratory_data[variable][subj_list]\n",
    "    behav_rank = rankdata(behav) # explicity convert the raw scores to ranks\n",
    "\n",
    "    behav_sim_nn = Adjacency(pairwise_distances(np.reshape(behav_rank, (-1, 1)), metric='euclidean'), matrix_type='distance')\n",
    "    behav_sim_nn.distance_to_similarity()\n",
    "    \n",
    "    behav_sims_nn[variable] = behav_sim_nn.distance_to_similarity()\n",
    "\n",
    "    plt.figure()\n",
    "    behav_sim_nn.plot()\n",
    "    plt.title(str(\"Behavioral similarity matrix (NN) \\n \" + variable), fontsize=12)\n",
    "    #plt.savefig(os.path.join(saving_directory + '/RDMs/new/exploratory-RDM-NN-' + variable + '.png'), dpi = 500)\n",
    "    plt.savefig(os.path.join(saving_directory + '/RDMs/new/exploratory-RDM-NN-' + variable + '_for_presentation.png'), dpi = 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b68f1ce-4400-4207-839a-908ef5f53e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "behav_sims_annak = dict() # creating dictionary to store matrices\n",
    "\n",
    "for variable in variables:\n",
    "    \n",
    "    behav = exploratory_data[variable][subj_list]\n",
    "    behav_rank = rankdata(behav) # explicity convert the raw scores to ranks\n",
    "    \n",
    "    behav_sim_annak = np.zeros((n_subs, n_subs))\n",
    "\n",
    "    # calculating Anna-K distance\n",
    "    for i in range(n_subs):\n",
    "        for j in range(n_subs):\n",
    "            if i < j:\n",
    "                sim_ij = np.mean([behav_rank[i], behav_rank[j]])/n_subs\n",
    "                behav_sim_annak[i,j] = sim_ij\n",
    "                behav_sim_annak[j,i] = sim_ij\n",
    "            elif i==j:\n",
    "                behav_sim_annak[i,j] = 1\n",
    "\n",
    "    # plotting and saving in dict\n",
    "    behav_sim_annak = Adjacency(behav_sim_annak, matrix_type='distance')\n",
    "    behav_sims_annak[variable] = behav_sim_annak\n",
    "\n",
    "    plt.figure()\n",
    "    behav_sim_annak.plot()\n",
    "    plt.title(str(\"Behavioral similarity matrix (AK) \\n \" + variable), fontsize=12)\n",
    "    #plt.savefig(os.path.join(saving_directory + '/RDMs/new/exploratory-RDM-AK-' + variable + '.png'), dpi = 500)\n",
    "    plt.savefig(os.path.join(saving_directory + '/RDMs/new/exploratory-RDM-AK-' + variable + '_for_presentation.png'), dpi = 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0661c0-c0e5-484c-a9df-922f627cd1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = np.array([\"social.ideology.scale\", \"social.identity.scale\", \n",
    "                      \"education_level\", \"background_SES\", \"sex\"])\n",
    "\n",
    "behav_sims_md = dict() # creating dictionary to store matrices\n",
    "\n",
    "for variable in variables:\n",
    "    \n",
    "    behav = exploratory_data[variable][subj_list]\n",
    "    behav_rank = rankdata(behav) # explicity convert the raw scores to ranks\n",
    "    \n",
    "    behav_sim_md = np.zeros((n_subs, n_subs))\n",
    "    \n",
    "    vi = np.cov(np.transpose(behav_rank))\n",
    "    vi = 1/vi # inverse?\n",
    "    \n",
    "    for i in range(n_subs):\n",
    "        for j in range(n_subs):\n",
    "            if i < j:\n",
    "                dist = scipy.spatial.distance.mahalanobis(u = behav_rank[i],\n",
    "                                                          v = behav_rank[j],\n",
    "                                                          VI = vi)\n",
    "                behav_sim_md[i,j] = dist\n",
    "                behav_sim_md[j,i] = dist\n",
    "            elif i==j:\n",
    "                behav_sim_md[i,j] = 1\n",
    "                                        \n",
    "    # plotting and saving in dict\n",
    "    behav_sim_md = Adjacency(behav_sim_md, matrix_type='distance')\n",
    "    behav_sims_md[variable] = behav_sim_md\n",
    "                                                        \n",
    "    plt.figure()\n",
    "    behav_sim_md.plot()\n",
    "    plt.title(str(\"Behavioral similarity matrix (MD) \\n \" + variable), fontsize=12)\n",
    "    plt.savefig(os.path.join(saving_directory + '/RDMs/new/exploratory-RDM-MD-' + variable + '.png'), dpi = 500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd290dfb-0583-444a-a3b5-50b72d7b2d7f",
   "metadata": {},
   "source": [
    "Now for the IS-RSA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d70c2bc-b89a-444f-815f-8cc9f922a4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "isrsa_nn, isrsa_annak, isrsa_md = {}, {}, {}\n",
    "for node in range(len(similarity_matrices)):\n",
    "    isrsa_nn[node] = similarity_matrices[node].similarity(behav_sim_nn, metric='spearman', n_permute=1, n_jobs=1 )['correlation']\n",
    "    isrsa_annak[node] = similarity_matrices[node].similarity(behav_sim_annak, metric='spearman', n_permute=1, n_jobs=1 )['correlation']\n",
    "    isrsa_md[node] = similarity_matrices[node].similarity(behav_sim_md, metric='spearman', n_permute=1, n_jobs=1 )['correlation']\n",
    "\n",
    "isrsa_nn_brain = roi_to_brain(pd.Series(isrsa_nn), expand_mask(mask))\n",
    "isrsa_annak_brain = roi_to_brain(pd.Series(isrsa_annak), expand_mask(mask))\n",
    "isrsa_md_brain = roi_to_brain(pd.Series(isrsa_md), expand_mask(mask))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4333a3-1c31-4505-b2b4-54d5f4c1538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the max absolute magnitude r_val across both sets of results so we can plot using the same colorscale\n",
    "vmax = np.max(np.abs([list(isrsa_nn.values()), \n",
    "                      list(isrsa_annak.values()),\n",
    "                     list(isrsa_md.values())\n",
    "                     ]))\n",
    "plt.figure()\n",
    "plot_stat_map(isrsa_nn_brain.to_nifti(), display_mode='x', cut_coords=8, vmax=vmax, title = \"NN\", cmap='RdBu_r')\n",
    "plt.savefig(os.path.join(saving_directory + '/brains/nn_model_comparison.png'), dpi = 500)\n",
    "\n",
    "plt.figure()\n",
    "plot_stat_map(isrsa_annak_brain.to_nifti(), display_mode='x', cut_coords=8, vmax=vmax, title = \"AnnaK\", cmap='RdBu_r')\n",
    "plt.savefig(os.path.join(saving_directory + '/brains/annak_model_comparison.png'), dpi = 500)\n",
    "\n",
    "plt.figure()\n",
    "plot_stat_map(isrsa_md_brain.to_nifti(), display_mode='x', cut_coords=8, vmax=vmax, title = \"MD\", cmap='RdBu_r')\n",
    "plt.savefig(os.path.join(saving_directory + '/brains/md_model_comparison.png'), dpi = 500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cae55e-7d7a-4e7f-9c99-378404843970",
   "metadata": {},
   "source": [
    "Now onto hypothesis testing!\n",
    "\n",
    "The next three cells loop over each of our five variables and compares the behavioural score RDM to the neural RDM by creating a null distribution through permuting 10,000 times (Mantel's test). We save the resulting data in one of four dictionaries, which are then saved as files for easy access without having to rerun the entire test. The difference between the dictionaries is whether the data being saved is correlation or _p_-value data, and whether it is nodewise or `nifti` data.\n",
    "\n",
    "Each cell runs the data from a different distance metric: the first is NN, the second is AK and the third is CDM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8cd41f-1a77-4faa-891e-280829e84c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "nifti_saving_dir = os.path.join(\"/home/c13572687/Documents/scripts_and_data/nifti_files_analysis/\")\n",
    "\n",
    "isrsa_nn_r_dict = dict()\n",
    "isrsa_nn_r_brain_dict = dict()\n",
    "isrsa_nn_p_dict = dict()\n",
    "isrsa_nn_p_brain_dict = dict()\n",
    "\n",
    "for variable in tqdm(variables):\n",
    "\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Starting with variable:\", variable)\n",
    "    print(\"Starting Time =\", current_time)\n",
    "\n",
    "    isrsa_nn_r, isrsa_nn_p = {}, {}\n",
    "    for node in tqdm(range(len(similarity_matrices))):\n",
    "        if node==0:\n",
    "            print(\"Doing node {} of {}...\".format(node+1, len(similarity_matrices)), end =\" \")\n",
    "        else:\n",
    "            print(\"{}..\".format(node+1), end = \" \")\n",
    "        stats_nn = similarity_matrices[node].similarity(behav_sims_nn[variable], metric='spearman', n_permute=10000, n_jobs=-1 )\n",
    "        isrsa_nn_r[node] = stats_nn['correlation']\n",
    "        isrsa_nn_r_dict[variable, node] = stats_nn['correlation']\n",
    "        isrsa_nn_p[node] = stats_nn['p']\n",
    "        isrsa_nn_p_dict[variable, node] = stats_nn['p']\n",
    "\n",
    "    isrsa_nn_r_brain = roi_to_brain(pd.Series(isrsa_nn_r), expand_mask(mask))\n",
    "    isrsa_nn_p_brain = roi_to_brain(pd.Series(isrsa_nn_p), expand_mask(mask))\n",
    "    \n",
    "    isrsa_nn_r_brain_dict[variable] = isrsa_nn_r_brain\n",
    "    isrsa_nn_p_brain_dict[variable] = isrsa_nn_p_brain\n",
    "    \n",
    "    file_name = str(\"isrsa_nn_r_brain_dict_\" + variable + \".nii\")\n",
    "    file_dir = os.path.join(nifti_saving_dir, file_name)\n",
    "    nib.save(isrsa_nn_r_brain_dict[variable].to_nifti(), file_dir)\n",
    "    print(file_dir, \"saved!\")\n",
    "    \n",
    "    file_name = str(\"isrsa_nn_p_brain_dict_\" + variable + \".nii\")\n",
    "    file_dir = os.path.join(nifti_saving_dir, file_name)\n",
    "    nib.save(isrsa_nn_p_brain_dict[variable].to_nifti(), file_dir)\n",
    "    print(file_dir, \"saved!\")\n",
    "    \n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Finshing Time =\", current_time)\n",
    "    \n",
    "np.save('isrsa_nn_r_dict.npy', isrsa_nn_r_dict) \n",
    "np.save('isrsa_nn_p_dict.npy', isrsa_nn_p_dict) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb583ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "isrsa_annak_r_dict = dict()\n",
    "isrsa_annak_r_brain_dict = dict()\n",
    "isrsa_annak_p_dict = dict()\n",
    "isrsa_annak_p_brain_dict = dict()\n",
    "\n",
    "for variable in tqdm(variables):\n",
    "\n",
    "    isrsa_annak_r, isrsa_annak_p = {}, {}\n",
    "    for node in tqdm(range(len(similarity_matrices))):\n",
    "        if node==0:\n",
    "            print(\"Doing node {} of {}...\".format(node+1, len(similarity_matrices)), end =\" \")\n",
    "        else:\n",
    "            print(\"{}..\".format(node+1), end = \" \")\n",
    "        stats_annak = similarity_matrices[node].similarity(behav_sims_annak[variable], metric='spearman', n_permute=10000, n_jobs=-1 )\n",
    "        isrsa_annak_r[node] = stats_annak['correlation']\n",
    "        isrsa_annak_r_dict[variable, node] = stats_annak['correlation']\n",
    "        isrsa_annak_p[node] = stats_annak['p']\n",
    "        isrsa_annak_p_dict[variable, node] = stats_annak['p']\n",
    "\n",
    "    isrsa_annak_r_brain = roi_to_brain(pd.Series(isrsa_annak_r), expand_mask(mask))\n",
    "    isrsa_annak_p_brain = roi_to_brain(pd.Series(isrsa_annak_p), expand_mask(mask))\n",
    "    \n",
    "    isrsa_annak_r_brain_dict[variable] = isrsa_annak_r_brain\n",
    "    isrsa_annak_p_brain_dict[variable] = isrsa_annak_p_brain\n",
    "\n",
    "    file_name = str(\"isrsa_annak_r_brain_dict_\" + variable + \".nii\")\n",
    "    file_dir = os.path.join(nifti_saving_dir, file_name)\n",
    "    nib.save(isrsa_nn_r_brain_dict[variable].to_nifti(), file_dir)\n",
    "    print(file_dir, \"saved!\")\n",
    "    \n",
    "    file_name = str(\"isrsa_annak_p_brain_dict_\" + variable + \".nii\")\n",
    "    file_dir = os.path.join(nifti_saving_dir, file_name)\n",
    "    nib.save(isrsa_nn_p_brain_dict[variable].to_nifti(), file_dir)\n",
    "    print(file_dir, \"saved!\")\n",
    "\n",
    "np.save('isrsa_annak_r_dict.npy', isrsa_annak_r_dict) \n",
    "np.save('isrsa_annak_p_dict.npy', isrsa_annak_p_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87027715",
   "metadata": {},
   "outputs": [],
   "source": [
    "isrsa_md_r_brain_dict = dict()\n",
    "isrsa_md_r_dict = dict()\n",
    "isrsa_md_p_brain_dict = dict()\n",
    "isrsa_md_p_dict = dict()\n",
    "\n",
    "for variable in tqdm(variables):\n",
    "\n",
    "    isrsa_md_r, isrsa_md_p = {}, {}\n",
    "    for node in tqdm(range(len(similarity_matrices))):\n",
    "        if node==0:\n",
    "            print(\"Doing node {} of {}...\".format(node+1, len(similarity_matrices)), end =\" \")\n",
    "        else:\n",
    "            print(\"{}..\".format(node+1), end = \" \")\n",
    "        stats_nn = similarity_matrices[node].similarity(behav_sims_md[variable], metric='spearman', n_permute=10000, n_jobs=-1 )\n",
    "        isrsa_md_r[node] = stats_nn['correlation']\n",
    "        isrsa_md_r_dict[variable, node] = stats_annak['correlation']\n",
    "        isrsa_md_p[node] = stats_nn['p']\n",
    "        isrsa_md_p_dict[variable, node] = stats_annak['p']\n",
    "\n",
    "    isrsa_md_r_brain = roi_to_brain(pd.Series(isrsa_md_r), expand_mask(mask))\n",
    "    isrsa_md_p_brain = roi_to_brain(pd.Series(isrsa_md_p), expand_mask(mask))\n",
    "    \n",
    "    isrsa_md_r_brain_dict[variable] = isrsa_md_r_brain\n",
    "    isrsa_md_p_brain_dict[variable] = isrsa_md_p_brain\n",
    "    \n",
    "    file_name = str(\"isrsa_md_r_brain_dict_\" + variable + \".nii\")\n",
    "    file_dir = os.path.join(nifti_saving_dir, file_name)\n",
    "    nib.save(isrsa_nn_r_brain_dict[variable].to_nifti(), file_dir)\n",
    "    print(file_dir, \"saved!\")\n",
    "    \n",
    "    file_name = str(\"isrsa_md_p_brain_dict_\" + variable + \".nii\")\n",
    "    file_dir = os.path.join(nifti_saving_dir, file_name)\n",
    "    nib.save(isrsa_nn_p_brain_dict[variable].to_nifti(), file_dir)\n",
    "    print(file_dir, \"saved!\")\n",
    "    \n",
    "\n",
    "np.save('isrsa_md_r_dict.npy', isrsa_md_r_dict) \n",
    "np.save('isrsa_md_p_dict.npy', isrsa_md_p_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812caf18-951f-431f-9979-c09ea6c06fbc",
   "metadata": {},
   "source": [
    "Now that we've finished looping over everything, we can visualize our results (both the correlations and _p_-values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785a88bd-3a78-4dfe-a214-aa128dded01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from nilearn import plotting\n",
    "cut_coords = (33,-28,15)\n",
    "\n",
    "saving_directory = os.path.dirname(\"/home/c13572687/Documents/scripts_and_data/figures/\")\n",
    "\n",
    "for variable in variables:\n",
    "    print('Nearest-Neighbor Model for', variable)\n",
    "    plotting.plot_stat_map(isrsa_nn_r_brain_dict[variable].to_nifti(), cut_coords=cut_coords,\n",
    "                       output_file=os.path.join(saving_directory + '/brains/nn_brain_correlations_' + variable + '.png'))\n",
    "    \n",
    "    plotting.plot_stat_map(isrsa_nn_p_brain_dict[variable].to_nifti(), cut_coords=cut_coords,\n",
    "                       output_file=os.path.join(saving_directory + '/brains/nn_brain_p_vals_' + variable + '.png'))\n",
    "\n",
    "    print('Anna K Model for', variable)\n",
    "    plotting.plot_stat_map(isrsa_annak_r_brain_dict[variable].to_nifti(), cut_coords=cut_coords,\n",
    "                       output_file=os.path.join(saving_directory + '/brains/annak_brain_correlations_' + variable + '.png'))\n",
    "    \n",
    "    plotting.plot_stat_map(isrsa_annak_p_brain_dict[variable].to_nifti(), cut_coords=cut_coords,\n",
    "                       output_file=os.path.join(saving_directory + '/brains/annak_brain_p_vals_' + variable + '.png'))\n",
    "\n",
    "    print('MD for', variable)\n",
    "    plotting.plot_stat_map(isrsa_md_r_brain_dict[variable].to_nifti(), cut_coords=cut_coords,\n",
    "                       output_file=os.path.join(saving_directory + '/brains/md_brain_correlations_' + variable + '.png'))\n",
    "    \n",
    "    plotting.plot_stat_map(isrsa_md_p_brain_dict[variable].to_nifti(), cut_coords=cut_coords,\n",
    "                       output_file=os.path.join(saving_directory + '/brains/md_brain_p_vals_' + variable + '.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5380a0f2-aef8-41b8-8fd0-a14ef28676ef",
   "metadata": {},
   "source": [
    "In a case where we want to load files (from an analysis we did before), we'll need this cell (make sure to run the first two cells beforehand!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df04e740-5d5d-42c7-b9c1-8c34bb92a578",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = np.array([\"social.ideology.scale\", \"social.identity.scale\", \n",
    "                      \"education_level\", \"background_SES\", \"sex\"])\n",
    "\n",
    "nifti_loading_dir = os.path.join(\"/home/c13572687/Documents/scripts_and_data/nifti_files_analysis/exploratory/\")\n",
    "\n",
    "isrsa_nn_r_brain_dict = dict()\n",
    "isrsa_nn_p_brain_dict = dict()\n",
    "isrsa_annak_r_brain_dict = dict()\n",
    "isrsa_annak_p_brain_dict = dict()\n",
    "isrsa_md_r_brain_dict = dict()\n",
    "isrsa_md_p_brain_dict = dict()\n",
    "\n",
    "for variable in tqdm(variables):\n",
    "    file_name = str(nifti_loading_dir + \"isrsa_nn_r_brain_dict_\" + variable + \".nii\")\n",
    "    file_dir = os.path.join(nifti_loading_dir, file_name)\n",
    "    isrsa_nn_r_brain_dict[variable] = Brain_Data(nib.load(file_dir))\n",
    "\n",
    "    file_name = str(nifti_loading_dir + \"isrsa_nn_p_brain_dict_\" + variable + \".nii\")\n",
    "    file_dir = os.path.join(nifti_loading_dir, file_name)\n",
    "    isrsa_nn_p_brain_dict[variable] = Brain_Data(nib.load(file_dir))\n",
    "    \n",
    "    file_name = str(nifti_loading_dir + \"isrsa_annak_r_brain_dict_\" + variable + \".nii\")\n",
    "    file_dir = os.path.join(nifti_loading_dir, file_name)\n",
    "    isrsa_annak_r_brain_dict[variable] = Brain_Data(nib.load(file_dir))\n",
    "\n",
    "    file_name = str(nifti_loading_dir + \"isrsa_annak_p_brain_dict_\" + variable + \".nii\")\n",
    "    file_dir = os.path.join(nifti_loading_dir, file_name)\n",
    "    isrsa_annak_p_brain_dict[variable] = Brain_Data(nib.load(file_dir))\n",
    "    \n",
    "    file_name = str(nifti_loading_dir + \"isrsa_md_r_brain_dict_\" + variable + \".nii\")\n",
    "    file_dir = os.path.join(nifti_loading_dir, file_name)\n",
    "    isrsa_md_r_brain_dict[variable] = Brain_Data(nib.load(file_dir))\n",
    "\n",
    "    file_name = str(nifti_loading_dir + \"isrsa_md_p_brain_dict_\" + variable + \".nii\")\n",
    "    file_dir = os.path.join(nifti_loading_dir, file_name)\n",
    "    isrsa_md_p_brain_dict[variable] = Brain_Data(nib.load(file_dir))\n",
    "\n",
    "np_loading_dir = os.path.join(\"/home/c13572687/Documents/scripts_and_data/numpy_files_analysis/exploratory/\")\n",
    "models = np.array(['nn', 'annak', 'md'])\n",
    "data_types = np.array(['r', 'p'])\n",
    "\n",
    "correlations_p_vals = dict()\n",
    "\n",
    "for model in tqdm(models):\n",
    "    for variable in variables:\n",
    "        for data_type in data_types:\n",
    "            correlations_p_vals[model, variable, data_type] = np.load(np_loading_dir + \"isrsa_\" + model + \"_\" + data_type + \"_dict.npy\", allow_pickle=True).item()\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9360c677-e5c6-48c9-aaea-c813f7f3866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_directory = os.path.dirname(\"/home/c13572687/Documents/scripts_and_data/figures/exploratory/\")\n",
    "\n",
    "for variable in variables:\n",
    "    plot_stat_map(isrsa_nn_r_brain_dict[variable].to_nifti(),\n",
    "                 title = variable + \", NN\", \n",
    "                 output_file=os.path.join(saving_directory + '/brains/nn_brain_correlations_' + variable + '.png'))\n",
    "    plot_stat_map(isrsa_annak_r_brain_dict[variable].to_nifti(),\n",
    "                 title = variable + \", Anna K\",\n",
    "                 output_file=os.path.join(saving_directory + '/brains/annak_brain_correlations_' + variable + '.png'))\n",
    "    plot_stat_map(isrsa_nn_p_brain_dict[variable].to_nifti(),\n",
    "                 title = variable + \", NN\", \n",
    "                 output_file=os.path.join(saving_directory + '/brains/nn_brain_p_vals_' + variable + '.png'))\n",
    "    plot_stat_map(isrsa_annak_p_brain_dict[variable].to_nifti(),\n",
    "                 title = variable + \", Anna K\", \n",
    "                 output_file=os.path.join(saving_directory + '/brains/annak_brain_correlations_' + variable + '.png'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77794e57-13d7-44bf-83a9-ff2dc46d58f7",
   "metadata": {},
   "source": [
    "We must correct our p-values for muliple comparison, and we use the Bonferroni-Holm correction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc520f9a-0715-43fb-8430-f5fb9f364f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "bonf_thrs_nn = dict()\n",
    "for variable in variables:\n",
    "    b_h_test = statsmodels.stats.multitest.multipletests((np.array(pd.Series(isrsa_nn_p_brain_dict[variable].data))), alpha=0.05, method='holm',  is_sorted=False, returnsorted=False)\n",
    "    bonf_thrs_nn[variable] = b_h_test[2]\n",
    "    print(f'Bonf-Holm Threshold: {np.round(bonf_thrs_nn[variable],7)}')\n",
    "\n",
    "bonf_thrs_annak = dict()\n",
    "for variable in variables:\n",
    "    b_h_test = statsmodels.stats.multitest.multipletests((np.array(pd.Series(isrsa_annak_p_brain_dict[variable].data))), alpha=0.05, method='holm',  is_sorted=False, returnsorted=False)\n",
    "    bonf_thrs_annak[variable] = b_h_test[2]\n",
    "    print(f'Bonf-Holm Threshold: {np.round(bonf_thrs_annak[variable],7)}')\n",
    "    \n",
    "bonf_thrs_md = dict()\n",
    "for variable in variables:\n",
    "    b_h_test = statsmodels.stats.multitest.multipletests((np.array(pd.Series(isrsa_md_p_brain_dict[variable].data))), alpha=0.05, method='holm',  is_sorted=False, returnsorted=False)\n",
    "    bonf_thrs_md[variable] = b_h_test[2]\n",
    "    print(f'Bonf-Holm Threshold: {np.round(bonf_thrs_md[variable],7)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c0e717-c723-4bec-b370-dcc92fffba5f",
   "metadata": {},
   "source": [
    "To discuss the potential results had they not had to be corrected for 4000 comparisons. In the following cell we extract the ten most significant _p_-values for each variable in the NN model and save these in a `numpy` file, which we'll then load in the confirmatory script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0c3157-e658-473e-a48b-0d7d0c662b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "isrsa_nn_p_dict = correlations_p_vals[\"nn\", \"social.ideology.scale\", data_type]\n",
    "most_sig_social_ideology = np.argsort(\n",
    "    np.fromiter(isrsa_nn_p_dict.values(), dtype = 'float')[0:268]\n",
    "    )[:10]\n",
    "\n",
    "most_sig_social_identity = np.argsort(\n",
    "    np.fromiter(isrsa_nn_p_dict.values(), dtype = 'float')[269:536]\n",
    "    )[:10]\n",
    "\n",
    "most_sig_education_level = np.argsort(\n",
    "    np.fromiter(isrsa_nn_p_dict.values(), dtype = 'float')[537:804]\n",
    "    )[:10]\n",
    "\n",
    "most_sig_background_SES = np.argsort(\n",
    "    np.fromiter(isrsa_nn_p_dict.values(), dtype = 'float')[805:1072]\n",
    "    )[:10]\n",
    "\n",
    "most_sig_sex = np.argsort(\n",
    "    np.fromiter(isrsa_nn_p_dict.values(), dtype = 'float')[1073:1340]\n",
    "    )[:10]\n",
    "\n",
    "\n",
    "np.save(\"most_sig_social_ideology_nn.npy\", most_sig_social_ideology)\n",
    "np.save(\"most_sig_social_identity_nn.npy\", most_sig_social_identity)\n",
    "np.save(\"most_sig_education_level_nn.npy\", most_sig_education_level)\n",
    "np.save(\"most_sig_background_SES_nn.npy\", most_sig_background_SES)\n",
    "np.save(\"most_sig_sex_nn.npy\", most_sig_sex)\n",
    "\n",
    "most_sig_social_ideology = np.argsort(\n",
    "    np.fromiter(isrsa_annak_p_dict.values(), dtype = 'float')[0:268]\n",
    "    )[:10]\n",
    "\n",
    "most_sig_social_identity = np.argsort(\n",
    "    np.fromiter(isrsa_annak_p_dict.values(), dtype = 'float')[269:536]\n",
    "    )[:10]\n",
    "\n",
    "most_sig_education_level = np.argsort(\n",
    "    np.fromiter(isrsa_annak_p_dict.values(), dtype = 'float')[537:804]\n",
    "    )[:10]\n",
    "\n",
    "most_sig_background_SES = np.argsort(\n",
    "    np.fromiter(isrsa_annak_p_dict.values(), dtype = 'float')[805:1072]\n",
    "    )[:10]\n",
    "\n",
    "most_sig_sex = np.argsort(\n",
    "    np.fromiter(isrsa_annak_p_dict.values(), dtype = 'float')[1073:1340]\n",
    "    )[:10]\n",
    "\n",
    "np.save(\"most_sig_social_ideology_annak.npy\", most_sig_social_ideology)\n",
    "np.save(\"most_sig_social_identity_annak.npy\", most_sig_social_identity)\n",
    "np.save(\"most_sig_education_level_annak.npy\", most_sig_education_level)\n",
    "np.save(\"most_sig_background_SES_annak.npy\", most_sig_background_SES)\n",
    "np.save(\"most_sig_sex_annak.npy\", most_sig_sex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
